{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4568e5-24a0-494d-ba1b-5ddfede89755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pymorphy2\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "with open('../data/russian.txt') as f:\n",
    "    stopwords = f.readlines()\n",
    "\n",
    "stopwords = [x.replace('\\n', '') for x in stopwords]\n",
    "stopwords = [x for x in stopwords if 'не' not in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6d64b-1029-47c8-837b-f31558f20db2",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41c5b23-af5b-4dd5-902d-6e249756b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "issuers_df = pd.read_excel('../data/issuers.xlsx', index_col = 0)\n",
    "issuers_plus_df = pd.read_excel('../data/issuers_plus.xlsx', index_col = 0)\n",
    "issuers_additional_df = pd.read_excel('../data/names and synonyms.xlsx')\n",
    "mentions_texts_df = pd.read_pickle('../data/mentions texts.pickle')\n",
    "sentiment_texts_df = pd.read_pickle('../data/sentiment_texts.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf96f5-f1da-4344-a4b1-ff18a64899f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d47831-8d21-4e02-bfa3-fb79572721ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>MessageID</th>\n",
       "      <th>issuerid</th>\n",
       "      <th>MessageText</th>\n",
       "      <th>DatePosted</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>EMITENT_FULL_NAME</th>\n",
       "      <th>EMITENT_ADDITIONAL_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001029560</td>\n",
       "      <td>1113</td>\n",
       "      <td>32</td>\n",
       "      <td>У «Ростелекома» вышло приложение «Аллё». Через...</td>\n",
       "      <td>2017-01-25 14:53:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Публичное акционерное общество \"Аэрофлот – рос...</td>\n",
       "      <td>Публичное акционерное общество \"Аэрофлот – рос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001029560</td>\n",
       "      <td>1177</td>\n",
       "      <td>62</td>\n",
       "      <td>Встречаем! Новая бумага на российском рынке ак...</td>\n",
       "      <td>2017-02-09 10:01:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Публичное акционерное общество \"Детский мир\"</td>\n",
       "      <td>Публичное акционерное общество \"Детский мир\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001029560</td>\n",
       "      <td>1501</td>\n",
       "      <td>26</td>\n",
       "      <td>Несколько мыслей о текущей ситуации на рынке и...</td>\n",
       "      <td>2017-05-04 06:02:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Акционерная финансовая корпорация \"Система\" А...</td>\n",
       "      <td>Публичное акционерное общество \"Акционерная фи...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ChannelID  MessageID  issuerid  \\\n",
       "0  1001029560       1113        32   \n",
       "1  1001029560       1177        62   \n",
       "2  1001029560       1501        26   \n",
       "\n",
       "                                         MessageText          DatePosted  \\\n",
       "0  У «Ростелекома» вышло приложение «Аллё». Через... 2017-01-25 14:53:12   \n",
       "1  Встречаем! Новая бумага на российском рынке ак... 2017-02-09 10:01:09   \n",
       "2  Несколько мыслей о текущей ситуации на рынке и... 2017-05-04 06:02:56   \n",
       "\n",
       "   SentimentScore                                  EMITENT_FULL_NAME  \\\n",
       "0             NaN  Публичное акционерное общество \"Аэрофлот – рос...   \n",
       "1             NaN       Публичное акционерное общество \"Детский мир\"   \n",
       "2             NaN  \"Акционерная финансовая корпорация \"Система\" А...   \n",
       "\n",
       "                             EMITENT_ADDITIONAL_NAME  \n",
       "0  Публичное акционерное общество \"Аэрофлот – рос...  \n",
       "1  Публичное акционерное общество \"Детский мир\", ...  \n",
       "2  Публичное акционерное общество \"Акционерная фи...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# добавим найденные синонимы \n",
    "issuers_df = issuers_df.drop(['EMITENT_FULL_NAME'], axis = 1).merge(issuers_plus_df[['issuerid', 'EMITENT_FULL_NAME']], on = 'issuerid')\n",
    "\n",
    "# добавим похожие названия\n",
    "cols  =['EMITENT_FULL_NAME', 'BGTicker', 'BGTicker.1'] + list(issuers_additional_df.loc[:,'Unnamed: 5':].columns)\n",
    "issuers_additional_df['EMITENT_ADDITIONAL_NAME'] = issuers_additional_df[cols].apply(lambda x: ', '.join(x[x.notnull()]), axis = 1)\n",
    "issuers_df= issuers_df.merge(issuers_additional_df[['issuerid', 'EMITENT_ADDITIONAL_NAME']], on = 'issuerid', how = 'inner', validate = '1:1')\n",
    "\n",
    "# приведем к виду сентимента\n",
    "mentions_texts_df['SentimentScore'] = np.nan\n",
    "keep_cols = ['ChannelID', 'MessageID', 'issuerid', 'DatePosted', 'MessageText', 'SentimentScore']\n",
    "\n",
    "# объединим дубли сентимента\n",
    "sentiment_texts_df = sentiment_texts_df[sentiment_texts_df['SentimentScore'] != 0].copy() # плохие оценки\n",
    "sentiment_texts_df = sentiment_texts_df.groupby(['ChannelID', 'MessageID', 'issuerid', 'MessageText', 'DatePosted'], as_index = False)['SentimentScore'].mean()\n",
    "sentiment_texts_df['SentimentScore'] = sentiment_texts_df['SentimentScore'].apply(np.ceil)\n",
    "\n",
    "# объединим mentions & sentiments\n",
    "df = pd.concat([mentions_texts_df[keep_cols], sentiment_texts_df[keep_cols]])\n",
    "df = df.groupby(['ChannelID', 'MessageID', 'issuerid', 'MessageText', 'DatePosted'], as_index = False)['SentimentScore'].max() # оставим только с оценкой\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# оставим только валидные компании\n",
    "df = df[df['issuerid'].isin(issuers_df['issuerid'])].copy()\n",
    "\n",
    "# добавим названия компаний\n",
    "df = df.merge(issuers_df[['issuerid', 'EMITENT_FULL_NAME', 'EMITENT_ADDITIONAL_NAME']], on = ['issuerid'], how = 'left', validate = 'm:1')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9eca8-a5dd-4907-baf3-d85e16bb5690",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f6c7ad-15ac-47f5-9f4b-9bc56f8189ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st task:\n",
      "Train: 17416 \n",
      "Test: 1446\n",
      "\n",
      "2nd task:\n",
      "Train: 7147 \n",
      "Test: 1927\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>MessageID</th>\n",
       "      <th>issuerid</th>\n",
       "      <th>MessageText</th>\n",
       "      <th>DatePosted</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>EMITENT_FULL_NAME</th>\n",
       "      <th>EMITENT_ADDITIONAL_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1041482399</td>\n",
       "      <td>97</td>\n",
       "      <td>58</td>\n",
       "      <td>#Дивиденды Черкизово с большой долей вероятнос...</td>\n",
       "      <td>2016-03-23 21:33:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Публичное акционерное общество \"Группа Черкизово\"</td>\n",
       "      <td>Публичное акционерное общество \"Группа Черкизо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1041482399</td>\n",
       "      <td>1207</td>\n",
       "      <td>152</td>\n",
       "      <td>Выручка Северстали в $. Славный бум 2011, 5 ле...</td>\n",
       "      <td>2016-07-21 11:41:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Публичное акционерное общество \"Северсталь\"</td>\n",
       "      <td>Публичное акционерное общество \"Северсталь\", C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041482399</td>\n",
       "      <td>1387</td>\n",
       "      <td>24</td>\n",
       "      <td>Итоги недели. Все те же Башнефть, Магнит и Лен...</td>\n",
       "      <td>2016-08-05 19:23:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Публичное акционерное общество \"Акрон\"</td>\n",
       "      <td>Публичное акционерное общество \"Акрон\", AKRN R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ChannelID  MessageID  issuerid  \\\n",
       "0  1041482399         97        58   \n",
       "1  1041482399       1207       152   \n",
       "2  1041482399       1387        24   \n",
       "\n",
       "                                         MessageText          DatePosted  \\\n",
       "0  #Дивиденды Черкизово с большой долей вероятнос... 2016-03-23 21:33:16   \n",
       "1  Выручка Северстали в $. Славный бум 2011, 5 ле... 2016-07-21 11:41:06   \n",
       "2  Итоги недели. Все те же Башнефть, Магнит и Лен... 2016-08-05 19:23:45   \n",
       "\n",
       "   SentimentScore                                  EMITENT_FULL_NAME  \\\n",
       "0             NaN  Публичное акционерное общество \"Группа Черкизово\"   \n",
       "1             NaN        Публичное акционерное общество \"Северсталь\"   \n",
       "2             NaN             Публичное акционерное общество \"Акрон\"   \n",
       "\n",
       "                             EMITENT_ADDITIONAL_NAME  \n",
       "0  Публичное акционерное общество \"Группа Черкизо...  \n",
       "1  Публичное акционерное общество \"Северсталь\", C...  \n",
       "2  Публичное акционерное общество \"Акрон\", AKRN R...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split by date\n",
    "df.sort_values(['DatePosted'], inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "split_date = df['DatePosted'].quantile(0.9) # ~2к для теста\n",
    "\n",
    "# general train / test\n",
    "train_df = df[df['DatePosted'] <= split_date].copy()\n",
    "test_df = df[df['DatePosted'] > split_date].copy()\n",
    "\n",
    "# 2nd task train / test\n",
    "train_sentiment_df = train_df[pd.notnull(train_df['SentimentScore'])].copy()\n",
    "test_sentiment_df = test_df[pd.notnull(test_df['SentimentScore'])].copy()\n",
    "\n",
    "# multi-label for f1-score\n",
    "test_df = test_df.groupby(['ChannelID', 'MessageID', 'MessageText'], as_index = False)['issuerid'].apply(list)\n",
    "\n",
    "# shapes\n",
    "print('1st task:\\nTrain:', train_df.shape[0], '\\nTest:', test_df.shape[0])\n",
    "print('\\n2nd task:\\nTrain:', train_sentiment_df.shape[0], '\\nTest:', test_sentiment_df.shape[0])\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ab28c0-c1bc-422d-912c-eb38300b66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log reg for company\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=stopwords, ngram_range=(1, 1))\n",
    "vectorizer.fit(issuers_df['EMITENT_ADDITIONAL_NAME'])\n",
    "\n",
    "# train vectors\n",
    "train_vectors, train_target = vectorizer.transform(pd.concat([train_df['MessageText'], issuers_df['EMITENT_ADDITIONAL_NAME']])), pd.concat([train_df['issuerid'], issuers_df['issuerid']])\n",
    "\n",
    "# predict & check\n",
    "clf_company = LogisticRegression(random_state=0, class_weight ='balanced', n_jobs = 8)\\\n",
    "                .fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9266f7c-0a86-44b4-9e19-c6e94fa45d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One class:  0.1972517054489638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gagarin/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# get test with multiple companies\n",
    "mlb = MultiLabelBinarizer(classes=issuers_df['issuerid'].values)\n",
    "test_vectors, test_target = vectorizer.transform(test_df['MessageText']), mlb.fit_transform(test_df['issuerid'])\n",
    "\n",
    "# just one class\n",
    "predict = mlb.transform([[x] for x in clf_company.predict(test_vectors)])\n",
    "print('One class: ', f1_score(test_target, predict, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0008f18f-8b2f-498c-bae8-7b23f4a8ac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5879605604566684"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log reg for sentiment\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words=stopwords, ngram_range=(1, 1))\n",
    "train_vectors, train_target = vectorizer.fit_transform(train_sentiment_df['MessageText']), train_sentiment_df['SentimentScore']\n",
    "test_vectors, test_target = vectorizer.transform(test_sentiment_df['MessageText']), test_sentiment_df['SentimentScore']\n",
    "clf_sentiment = LogisticRegression(random_state=0, n_jobs = 8)\\\n",
    "                    .fit(train_vectors, train_target)\n",
    "\n",
    "accuracy_score(test_target, clf_sentiment.predict(test_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06a0c2-9340-4343-b46b-27bca4fc01ce",
   "metadata": {},
   "source": [
    "## Train final artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0461e-8dad-49cf-9edd-83a98c31034a",
   "metadata": {},
   "source": [
    "**company**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3f48d5-9834-4d9e-8ee8-8ac62e941377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/clf_company.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log reg for company\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words=stopwords, ngram_range=(1, 1))\n",
    "vectorizer.fit(issuers_df['EMITENT_ADDITIONAL_NAME'])\n",
    "\n",
    "train_vectors, train_target = vectorizer.transform(pd.concat([df['MessageText'], issuers_df['EMITENT_ADDITIONAL_NAME']])), \\\n",
    "            pd.concat([df['issuerid'], issuers_df['issuerid']])\n",
    "\n",
    "# predict & check\n",
    "clf_company = LogisticRegression(random_state=0, class_weight ='balanced', n_jobs = 8)\\\n",
    "                .fit(train_vectors, train_target)\n",
    "\n",
    "# save vectorizer and model\n",
    "joblib.dump(vectorizer, '../model/vectorizer_company.pkl')\n",
    "joblib.dump(clf_company, '../model/clf_company.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7999862-e034-44fc-aa82-055291ecb3af",
   "metadata": {},
   "source": [
    "**sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6339e63-733c-45de-b6f0-42056206f0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/clf_sentiment.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = df[pd.notnull(df['SentimentScore'])].copy()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words=stopwords, ngram_range=(1, 1))\n",
    "train_vectors, train_target = vectorizer.fit_transform(df_sentiment['MessageText']), df_sentiment['SentimentScore']\n",
    "\n",
    "# train\n",
    "clf_sentiment = LogisticRegression(random_state=0, n_jobs = 8)\\\n",
    "                    .fit(train_vectors, train_target)\n",
    "\n",
    "# save model\n",
    "joblib.dump(vectorizer, '../model/vectorizer_sentiment.pkl')\n",
    "joblib.dump(clf_sentiment, '../model/clf_sentiment.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219daeba-5e8d-427b-9a2e-08e7e0463cb0",
   "metadata": {},
   "source": [
    "**check prod**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e14e0f8-f0b4-4a65-a14a-6d76914f631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/test_texts.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "companies = [int(x) for x in joblib.load('../model/clf_company.pkl').predict(joblib.load('../model/vectorizer_company.pkl').transform(data))]\n",
    "sentiments = [float(x) for x in joblib.load('../model/clf_sentiment.pkl').predict(joblib.load('../model/vectorizer_sentiment.pkl').transform(data))]\n",
    "result = [[pair] for pair in zip(companies, sentiments)]\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gagarin",
   "language": "python",
   "name": "gagarin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
